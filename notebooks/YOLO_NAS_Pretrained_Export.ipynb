{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rmuF9iKWTbdk",
        "outputId": "67c549b4-178a-452b-c9ff-97e042125f42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q roboflow==1.1.49\n",
        "!pip install -q supervision==0.25.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/Deci-AI/super-gradients.git@stable\n",
        "! sed -i 's/sghub.deci.ai/sg-hub-nv.s3.amazonaws.com/' /usr/local/lib/python3.11/dist-packages/super_gradients/training/pretrained_models.py\n",
        "! sed -i 's/sghub.deci.ai/sg-hub-nv.s3.amazonaws.com/' /usr/local/lib/python3.11/dist-packages/super_gradients/training/utils/checkpoint_utils.py"
      ],
      "metadata": {
        "id": "HdcbMVT8kZnN",
        "outputId": "53e3b4e7-a8c0-4873-e402-6e08fb2a8fde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Cannot install super-gradients and super-gradients==3.7.1+master because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dTB0jy_NNSFz",
        "outputId": "26d7f888-2c4f-4e0e-82e0-6a55b40551cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The console stream is logged into /root/sg_logs/console.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-07-05 12:32:37] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n",
            "[2025-07-05 12:32:45] INFO - utils.py - NumExpr defaulting to 2 threads.\n",
            "DEBUG:2025-07-05 12:32:48,013:jax._src.path:31: etils.epath found. Using etils.epath for file I/O.\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "[2025-07-05 12:32:51] INFO - env_sanity_check.py - Library check is not supported when super_gradients installed through \"git+https://github.com/...\" command\n",
            "[2025-07-05 12:32:51] WARNING - checkpoint_utils.py - :warning: The pre-trained models provided by SuperGradients may have their own licenses or terms and conditions derived from the dataset used for pre-training.\n",
            " It is your responsibility to determine whether you have permission to use the models for your use case.\n",
            " The model you have requested was pre-trained on the coco dataset, published under the following terms: https://cocodataset.org/#termsofuse\n",
            "[2025-07-05 12:32:51] INFO - checkpoint_utils.py - License Notification: YOLO-NAS pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
            "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS.md\n",
            "By downloading the pre-trained weight files you agree to comply with these terms.\n",
            "[2025-07-05 12:32:52] INFO - checkpoint_utils.py - Successfully loaded pretrained weights for architecture yolo_nas_s\n"
          ]
        }
      ],
      "source": [
        "from super_gradients.common.object_names import Models\n",
        "from super_gradients.conversion import DetectionOutputFormatMode\n",
        "from super_gradients.training import models\n",
        "\n",
        "model = models.get(Models.YOLO_NAS_S, pretrained_weights=\"coco\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Gvb7Q9ABioironBh8wxr\")\n",
        "project = rf.workspace(\"counting-d5gqi\").project(\"general-2-ixcjy\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov5\")\n"
      ],
      "metadata": {
        "id": "EQBNi2QIirLI",
        "outputId": "dec37f97-ae97-4b4d-c9d6-c803ad99ff1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.11/dist-packages (1.1.49)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.6.15)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.2.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.58.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.2)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LOCATION = dataset.location\n",
        "print(\"location:\", LOCATION)\n",
        "CLASSES = sorted(project.classes.keys())\n",
        "print(\"classes:\", CLASSES)"
      ],
      "metadata": {
        "id": "7r1mRGmEkInD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ARCH = 'yolo_nas_s'\n",
        "BATCH_SIZE = 8\n",
        "MAX_EPOCHS = 25\n",
        "CHECKPOINT_DIR = '/checkpoints'\n",
        "EXPERIMENT_NAME = project.name.lower().replace(\" \", \"_\")"
      ],
      "metadata": {
        "id": "0SCv5H7zk5o6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import Trainer\n",
        "\n",
        "trainer = Trainer(experiment_name=EXPERIMENT_NAME, ckpt_root_dir=CHECKPOINT_DIR)"
      ],
      "metadata": {
        "id": "Md63svyblAtV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_params = {\n",
        "    'data_dir': LOCATION,\n",
        "    'train_images_dir':'train/images',\n",
        "    'train_labels_dir':'train/labels',\n",
        "    'val_images_dir':'valid/images',\n",
        "    'val_labels_dir':'valid/labels',\n",
        "    'test_images_dir':'test/images',\n",
        "    'test_labels_dir':'test/labels',\n",
        "    'classes': CLASSES\n",
        "}"
      ],
      "metadata": {
        "id": "LxIOTsPflCTQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training.dataloaders.dataloaders import (\n",
        "    coco_detection_yolo_format_train, coco_detection_yolo_format_val)\n",
        "\n",
        "train_data = coco_detection_yolo_format_train(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['train_images_dir'],\n",
        "        'labels_dir': dataset_params['train_labels_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'num_workers': 2\n",
        "    }\n",
        ")\n",
        "\n",
        "val_data = coco_detection_yolo_format_val(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['val_images_dir'],\n",
        "        'labels_dir': dataset_params['val_labels_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'num_workers': 2\n",
        "    }\n",
        ")\n",
        "\n",
        "test_data = coco_detection_yolo_format_val(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['test_images_dir'],\n",
        "        'labels_dir': dataset_params['test_labels_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'num_workers': 2\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "qAf6W4omjVPn",
        "outputId": "3a10dd07-a119-4a23-a8fc-a297dbe9f679",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-07-05 12:37:12] INFO - detection_dataset.py - Dataset Initialization in progress. `cache_annotations=True` causes the process to take longer due to full dataset indexing.\n",
            "Indexing dataset annotations: 100%|██████████| 11127/11127 [00:01<00:00, 5565.25it/s]\n",
            "[2025-07-05 12:37:14] WARNING - detection_dataset.py - Found 132390 invalid bbox that were ignored. For more information, please set `show_all_warnings=True`.\n",
            "[2025-07-05 12:37:14] INFO - detection_dataset.py - Dataset Initialization in progress. `cache_annotations=True` causes the process to take longer due to full dataset indexing.\n",
            "Indexing dataset annotations: 100%|██████████| 480/480 [00:00<00:00, 6857.99it/s]\n",
            "[2025-07-05 12:37:14] WARNING - detection_dataset.py - Found 5941 invalid bbox that were ignored. For more information, please set `show_all_warnings=True`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.dataset.transforms"
      ],
      "metadata": {
        "id": "c8mW5pgGkHcg",
        "outputId": "1cabe583-fc8f-4c3c-fe4e-02f9ea1a677e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<super_gradients.training.transforms.transforms.DetectionMosaic at 0x7d307fc400d0>,\n",
              " <super_gradients.training.transforms.transforms.DetectionRandomAffine at 0x7d307fd22c50>,\n",
              " <super_gradients.training.transforms.transforms.DetectionMixup at 0x7d30816a4490>,\n",
              " <super_gradients.training.transforms.transforms.DetectionHSV at 0x7d307fd22d10>,\n",
              " <super_gradients.training.transforms.transforms.DetectionHorizontalFlip at 0x7d307fd22d90>,\n",
              " <super_gradients.training.transforms.transforms.DetectionPaddedRescale at 0x7d307fd22e50>,\n",
              " <super_gradients.training.transforms.transforms.DetectionTargetsFormatTransform at 0x7d307fd22e90>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import models\n",
        "\n",
        "model = models.get(\n",
        "    MODEL_ARCH,\n",
        "    num_classes=len(dataset_params['classes']),\n",
        "    pretrained_weights=\"coco\"\n",
        ")"
      ],
      "metadata": {
        "id": "hFKqS5n6jdZy",
        "outputId": "6b4f4876-8dc9-49ae-e4b8-ec6878d2d68d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-07-05 12:34:30] WARNING - checkpoint_utils.py - :warning: The pre-trained models provided by SuperGradients may have their own licenses or terms and conditions derived from the dataset used for pre-training.\n",
            " It is your responsibility to determine whether you have permission to use the models for your use case.\n",
            " The model you have requested was pre-trained on the coco dataset, published under the following terms: https://cocodataset.org/#termsofuse\n",
            "[2025-07-05 12:34:30] INFO - checkpoint_utils.py - License Notification: YOLO-NAS pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
            "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS.md\n",
            "By downloading the pre-trained weight files you agree to comply with these terms.\n",
            "[2025-07-05 12:34:30] INFO - checkpoint_utils.py - Successfully loaded pretrained weights for architecture yolo_nas_s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training.losses import PPYoloELoss\n",
        "from super_gradients.training.metrics import DetectionMetrics_050\n",
        "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n",
        "\n",
        "train_params = {\n",
        "    'silent_mode': True,\n",
        "    \"average_best_models\":False,\n",
        "    \"warmup_mode\": \"linear_epoch_step\",\n",
        "    \"warmup_initial_lr\": 1e-6,\n",
        "    \"lr_warmup_epochs\": 3,\n",
        "    \"initial_lr\": 5e-4,\n",
        "    \"lr_mode\": \"cosine\",\n",
        "    \"cosine_final_lr_ratio\": 0.1,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"optimizer_params\": {\"weight_decay\": 0.0001},\n",
        "    \"zero_weight_decay_on_bias_and_bn\": True,\n",
        "    \"ema\": True,\n",
        "    \"ema_params\": {\"decay\": 0.9, \"decay_type\": \"threshold\"},\n",
        "    \"max_epochs\": MAX_EPOCHS,\n",
        "    \"mixed_precision\": True,\n",
        "    \"loss\": PPYoloELoss(\n",
        "        use_static_assigner=False,\n",
        "        num_classes=len(dataset_params['classes']),\n",
        "        reg_max=16\n",
        "    ),\n",
        "    \"valid_metrics_list\": [\n",
        "        DetectionMetrics_050(\n",
        "            score_thres=0.1,\n",
        "            top_k_predictions=300,\n",
        "            num_cls=len(dataset_params['classes']),\n",
        "            normalize_targets=True,\n",
        "            post_prediction_callback=PPYoloEPostPredictionCallback(\n",
        "                score_threshold=0.01,\n",
        "                nms_top_k=1000,\n",
        "                max_predictions=300,\n",
        "                nms_threshold=0.7\n",
        "            )\n",
        "        )\n",
        "    ],\n",
        "    \"metric_to_watch\": 'mAP@0.50'\n",
        "}"
      ],
      "metadata": {
        "id": "GeXJR1salPjf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(\n",
        "    model=model,\n",
        "    training_params=train_params,\n",
        "    train_loader=train_data,\n",
        ")"
      ],
      "metadata": {
        "id": "62PMcJP8lROq",
        "outputId": "6bb3066c-25c2-4511-cd98-916cf7a33172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-07-05 12:38:12] INFO - sg_trainer.py - Starting a new run with `run_id=RUN_20250705_123812_393304`\n",
            "[2025-07-05 12:38:12] INFO - sg_trainer.py - Checkpoints directory: /checkpoints/general_2/RUN_20250705_123812_393304\n",
            "[2025-07-05 12:38:12] INFO - sg_trainer.py - Using EMA with params {'decay': 0.9, 'decay_type': 'threshold'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The console stream is now moved to /checkpoints/general_2/RUN_20250705_123812_393304/console_Jul05_12_38_12.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Object name `linear_epoch_step` is now deprecated. Please replace it with `LinearEpochLRWarmup`.\n",
            "initialize_param_groups and update_param_groups usages are deprecated since 3.4.0, will be removed in 3.5.0 and have no effect. \n",
            " Assign different learning rates by passing a mapping of layer name prefixes to lr values through initial_lr training hyperparameter (i.e initial_lr={'backbone': 0.01, 'default':0.1})\n",
            "`torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "[2025-07-05 12:38:15] INFO - sg_trainer_utils.py - TRAINING PARAMETERS:\n",
            "    - Mode:                         Single GPU\n",
            "    - Number of GPUs:               1          (1 available on the machine)\n",
            "    - Full dataset size:            189        (len(train_set))\n",
            "    - Batch size per GPU:           8          (batch_size)\n",
            "    - Batch Accumulate:             1          (batch_accumulate)\n",
            "    - Total batch size:             8          (num_gpus * batch_size)\n",
            "    - Effective Batch size:         8          (num_gpus * batch_size * batch_accumulate)\n",
            "    - Iterations per epoch:         23         (len(train_loader))\n",
            "    - Gradient updates per epoch:   23         (len(train_loader) / batch_accumulate)\n",
            "    - Model: YoloNAS_S  (19.02M parameters, 19.02M optimized)\n",
            "    - Learning Rates and Weight Decays:\n",
            "      - default: (19.02M parameters). LR: 0.0005 (19.02M parameters) WD: 0.0, (42.17K parameters), WD: 0.0001, (18.98M parameters)\n",
            "\n",
            "[2025-07-05 12:38:15] WARNING - sg_trainer.py - Could not set preprocessing pipeline from the validation dataset:\n",
            " get_equivalent_preprocessing is not implemented for non-deterministic transforms..\n",
            " Before callingpredict make sure to call set_dataset_processing_params.\n",
            "[2025-07-05 12:38:15] INFO - sg_trainer.py - Started training for 25 epochs (0/24)\n",
            "\n",
            "Train epoch 0:   0%|          | 0/23 [00:00<?, ?it/s]`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "Train epoch 0: 100%|██████████| 23/23 [00:12<00:00,  1.90it/s, PPYoloELoss/loss=4.56, PPYoloELoss/loss_cls=2.6, PPYoloELoss/loss_dfl=0.953, PPYoloELoss/loss_iou=1.01, gpu_mem=3.33]\n",
            "Validating: 100%|██████████| 23/23 [00:09<00:00,  2.31it/s]\n",
            "[2025-07-05 12:38:38] WARNING - sg_trainer.py - Could not set preprocessing pipeline from the validation dataset:\n",
            " get_equivalent_preprocessing is not implemented for non-deterministic transforms..\n",
            " Before callingpredict make sure to call set_dataset_processing_params.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnpicklingError",
          "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray._reconstruct was not an allowed global by default. Please use `torch.serialization.add_safe_globals([_reconstruct])` or the `torch.serialization.safe_globals([_reconstruct])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-21-404415407.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trainer.train(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtraining_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/super_gradients/training/sg_trainer/sg_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, training_params, train_loader, valid_loader, test_loaders, additional_configs_to_log)\u001b[0m\n\u001b[1;32m   1623\u001b[0m                     \u001b[0;31m# SAVING AND LOGGING OCCURS ONLY IN THE MAIN PROCESS (IN CASES THERE ARE SEVERAL PROCESSES - DDP)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mshould_run_validation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m                         self._save_checkpoint(\n\u001b[0m\u001b[1;32m   1626\u001b[0m                             \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m                             \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/super_gradients/training/sg_trainer/sg_trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, optimizer, epoch, train_metrics_dict, validation_results_dict, context)\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_best_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0mnet_for_averaging\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"net\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_weight_averaging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_average_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_for_averaging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_results_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_results_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;31m# REMOVE UNNECESSARY ITEMS FROM AVERAGED STATE DICT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/super_gradients/training/utils/weight_averaging_utils.py\u001b[0m in \u001b[0;36mget_average_model\u001b[0;34m(self, model, validation_results_dict)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# If validation tuple is provided, update the average model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_results_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0maveraging_snapshots_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_snapshots_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_results_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0maveraging_snapshots_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_averaging_snapshots_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/super_gradients/training/utils/weight_averaging_utils.py\u001b[0m in \u001b[0;36mupdate_snapshots_dict\u001b[0;34m(self, model, validation_results_dict)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mvalidation_results_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mperformance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatest\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \"\"\"\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0maveraging_snapshots_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_averaging_snapshots_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# IF CURRENT MODEL IS BETTER, TAKING HIS PLACE IN ACC LIST AND OVERWRITE THE NEW AVERAGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/super_gradients/training/utils/weight_averaging_utils.py\u001b[0m in \u001b[0;36m_get_averaging_snapshots_dict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_averaging_snapshots_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maveraging_snapshots_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1468\u001b[0m                         )\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m                 return _load(\n\u001b[1;32m   1472\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray._reconstruct was not an allowed global by default. Please use `torch.serialization.add_safe_globals([_reconstruct])` or the `torch.serialization.safe_globals([_reconstruct])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GymUghyCNXem"
      },
      "outputs": [],
      "source": [
        "# export the model for compatibility with Frigate\n",
        "\n",
        "model.export(\"yolo_nas_s.onnx\",\n",
        "             output_predictions_format=DetectionOutputFormatMode.FLAT_FORMAT,\n",
        "             max_predictions_per_image=20,\n",
        "             num_pre_nms_predictions=300,\n",
        "             confidence_threshold=0.4,\n",
        "             input_image_shape=(320,320),\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBhXV5g4Nh42"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('yolo_nas_s.onnx')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}